{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasetX = torch.Tensor(10000, 2);\n",
    "datasetY = torch.Tensor(10000, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[counter = 1\n",
    "start = 1\n",
    "end = 400\n",
    "val = -2\n",
    "for (x in 1:500) {\n",
    "  ass4df[start:end, 1] = rep(val, 400)\n",
    "  ass4df[start:end, 2] = seq(-2,1.99, 0.01)\n",
    "  #ass4df[counter, 3] = 2*x^2 + 3*y^2 + 1\n",
    "  start = start + 400\n",
    "  end = end + 400\n",
    "  val = val + 0.01\n",
    "} ]]\n",
    "--start = 1;\n",
    "--endd = 400;\n",
    "vali = -2;\n",
    "counter = 1\n",
    "for i=1,100 do\n",
    "    valj = -2;\n",
    "    for j=1,100 do\n",
    "        datasetX[counter][1] = vali;\n",
    "        datasetX[counter][2] = valj;\n",
    "        datasetY[counter] = 2*vali^2 - 3*valj^2 + 1;\n",
    "        valj = valj + 0.1;\n",
    "        counter = counter + 1;\n",
    "    end\n",
    "    vali = vali + 0.1;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0000\n",
       " 1.0000\n",
       "[torch.DoubleTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetX[3031]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.round(datasetY*10000)*0.00001; --round to 5 decimal places\n",
    "print(y[3031])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.cat(y, datasetX, 2);\n",
    "print(f[3031])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'optim'\n",
    "require 'nn'\n",
    "\n",
    "-- We will write the loss to a text file and read from there to plot the loss as training proceeds\n",
    "logger = optim.Logger('loss_log.txt')\n",
    "--[[\n",
    "data = torch.Tensor{\n",
    "   {40,  6,  4},\n",
    "   {44, 10,  4},\n",
    "   {46, 12,  5},\n",
    "   {48, 14,  7},\n",
    "   {52, 16,  9},\n",
    "   {58, 18, 12},\n",
    "   {60, 22, 14},\n",
    "   {68, 24, 20},\n",
    "   {74, 26, 21},\n",
    "   {80, 32, 24}\n",
    "}]]\n",
    "data = f;\n",
    "\n",
    "model = nn.Sequential()                 -- define the container\n",
    "ninputs = 2; noutputs = 6\n",
    "model:add(nn.Linear(ninputs, noutputs)) -- define the only module\n",
    "--model:add(nn.Tanh())\n",
    "--model:add(nn.Linear(noutputs, 1))\n",
    "criterion = nn.MSECriterion()\n",
    "x, dl_dx = model:getParameters()\n",
    "\n",
    "feval = function(x_new)\n",
    "   -- set x to x_new, if differnt\n",
    "   -- (in this simple example, x_new will typically always point to x,\n",
    "   -- so the copy is really useless)\n",
    "   if x ~= x_new then\n",
    "      x:copy(x_new)\n",
    "   end\n",
    "\n",
    "   -- select a new training sample\n",
    "   _nidx_ = (_nidx_ or 0) + 1\n",
    "   if _nidx_ > (#data)[1] then _nidx_ = 1 end\n",
    "\n",
    "   local sample = data[_nidx_]\n",
    "   local target = sample[{ {1} }]      -- this funny looking syntax allows\n",
    "   local inputs = sample[{ {2,3} }]    -- slicing of arrays.\n",
    "\n",
    "   -- reset gradients (gradients are always accumulated, to accommodate \n",
    "   -- batch methods)\n",
    "   dl_dx:zero()\n",
    "\n",
    "   -- evaluate the loss function and its derivative wrt x, for that sample\n",
    "   local loss_x = criterion:forward(model:forward(inputs), target)\n",
    "   model:backward(inputs, criterion:backward(model.output, target))\n",
    "\n",
    "   -- return loss(x) and dloss/dx\n",
    "   return loss_x, dl_dx\n",
    "end\n",
    "\n",
    "sgd_params = {\n",
    "   learningRate = 1e-3,\n",
    "   learningRateDecay = 1e-4,\n",
    "   weightDecay = 0,\n",
    "   momentum = 0\n",
    "}\n",
    "\n",
    "for i = 1,1e4 do\n",
    "   -- this variable is used to estimate the average loss\n",
    "   current_loss = 0\n",
    "   -- an epoch is a full loop over our training data\n",
    "   for i = 1,(#data)[1] do\n",
    "      _,fs = optim.sgd(feval,x,sgd_params)\n",
    "      current_loss = current_loss + fs[1]\n",
    "   end\n",
    "   -- report average error on epoch\n",
    "   current_loss = current_loss / (#data)[1]\n",
    "   print('current loss = ' .. current_loss)\n",
    "   \n",
    "   logger:add{['training error'] = current_loss}\n",
    "   logger:style{['training error'] = '-'}\n",
    "   logger:plot()  \n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "text = {40.32, 42.92, 45.33, 48.85, 52.37, 57, 61.82, 69.78, 72.19, 79.42}\n",
    "\n",
    "print('id  approx   text')\n",
    "for i = 1,(#data)[1] do\n",
    "   local myPrediction = model:forward(data[i][{{2,3}}])\n",
    "   print(string.format(\"%2d  %6.2f %6.2f\", i, myPrediction[1], text[i]))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
